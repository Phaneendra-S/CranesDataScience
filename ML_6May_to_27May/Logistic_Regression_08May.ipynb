{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e568eb00-cf8d-4329-af57-2cd449526e6e",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d36ceeb-b24f-4cdb-a3ba-843723906192",
   "metadata": {},
   "source": [
    "- logistic regression is used for classification(mainly used for binary classification)                   \n",
    "- it predicts whether something belongs to one category or another(eg:spam or not spam)                    \n",
    "- instead of predicting actual values(like in Linear Regression), it predicts probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116f624e-c054-4cce-9453-d3de090fc290",
   "metadata": {},
   "source": [
    "It uses a special function called the sigmoid function(logistic function)            \n",
    "                        sigma(y)=1/1+e^-y                                \n",
    "this gives you the probability of class 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd5906-2f7d-4629-ba54-fd55f6135814",
   "metadata": {},
   "source": [
    "the function squeezes any value into a range between 0 and 1                         \n",
    "if the result is closer to 1, we calssify it as one category(eg: yes)\n",
    "if the result is closer to 0, we classify it to other category(eg: no)                \n",
    "P(y=0|x)=1-P(y=1|x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79868847-0c8d-424e-8f51-531b0078233f",
   "metadata": {},
   "source": [
    "Logistic regression makes decisions based on probalities:                  \n",
    "if probability >= 0.5, it predicts 1                     \n",
    "if probability < 0.5, it predicts 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82167a6d-961a-47b1-874a-66248f8ed250",
   "metadata": {},
   "source": [
    "Logistic regression makes predictions using  this formula:                  \n",
    "\n",
    "sigma(x)=1/1+e^-(b0+b1x1+b2x2+...+bnxn)                                \n",
    "\n",
    "b0,b1,b2,... are weights(parameters) that the model learns                               \n",
    "x1,x2,x3,..... are the inout features(eg: age, height, salary etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d34fc9-bd8e-41d0-b530-da2ae9ee8750",
   "metadata": {},
   "source": [
    "**Multi class logistic regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7824343-cda8-4373-a843-4e7b5df71bed",
   "metadata": {},
   "source": [
    "- if there are more than 2 categories, we use softmax Regressioninstead of logistic regression\n",
    "- the softmax function assigns probabilities to all classes and picks one most likely one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f63264-7a0a-465c-b932-21a5b28eeae2",
   "metadata": {},
   "source": [
    "**Advantages**\n",
    "- Simple and easy to implement\n",
    "- Worls well for binary calssification\n",
    "- Fast and efficient\n",
    "- Provides probability scores                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f307f67-eaa7-4a4a-ba97-9b58b867d0be",
   "metadata": {},
   "source": [
    "**Disadvantages**\n",
    "- Assumes a linear relation between features and the outcome\n",
    "- Not great for complex, non linear data\n",
    "- Sensitive to outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2797bf49-f976-419a-8837-4d465767b9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
