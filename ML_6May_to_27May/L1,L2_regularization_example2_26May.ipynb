{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9aae055-bf8f-4770-99a4-4f5155584735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b03cbfd-87fb-459f-8aff-f50ec35c6299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_41</th>\n",
       "      <th>feature_42</th>\n",
       "      <th>feature_43</th>\n",
       "      <th>feature_44</th>\n",
       "      <th>feature_45</th>\n",
       "      <th>feature_46</th>\n",
       "      <th>feature_47</th>\n",
       "      <th>feature_48</th>\n",
       "      <th>feature_49</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.149553</td>\n",
       "      <td>0.376510</td>\n",
       "      <td>-1.891904</td>\n",
       "      <td>-0.840981</td>\n",
       "      <td>-0.309501</td>\n",
       "      <td>-0.750899</td>\n",
       "      <td>-2.092533</td>\n",
       "      <td>1.166785</td>\n",
       "      <td>0.418648</td>\n",
       "      <td>0.026553</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.505302</td>\n",
       "      <td>0.662250</td>\n",
       "      <td>0.265463</td>\n",
       "      <td>-0.257552</td>\n",
       "      <td>-0.199983</td>\n",
       "      <td>1.454656</td>\n",
       "      <td>-2.043937</td>\n",
       "      <td>-2.478008</td>\n",
       "      <td>0.737513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030191</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>-0.191048</td>\n",
       "      <td>0.192283</td>\n",
       "      <td>-0.024028</td>\n",
       "      <td>-0.463269</td>\n",
       "      <td>1.182454</td>\n",
       "      <td>-0.593840</td>\n",
       "      <td>0.449656</td>\n",
       "      <td>1.101156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584503</td>\n",
       "      <td>-0.998030</td>\n",
       "      <td>-0.241414</td>\n",
       "      <td>-0.709572</td>\n",
       "      <td>-0.135254</td>\n",
       "      <td>0.211817</td>\n",
       "      <td>-0.219444</td>\n",
       "      <td>1.347727</td>\n",
       "      <td>-0.747078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.240354</td>\n",
       "      <td>1.532933</td>\n",
       "      <td>-0.679733</td>\n",
       "      <td>-1.006590</td>\n",
       "      <td>-0.382227</td>\n",
       "      <td>-0.067230</td>\n",
       "      <td>-0.442423</td>\n",
       "      <td>-0.139050</td>\n",
       "      <td>-0.566511</td>\n",
       "      <td>0.289654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341175</td>\n",
       "      <td>-1.045214</td>\n",
       "      <td>-1.320925</td>\n",
       "      <td>1.394625</td>\n",
       "      <td>-1.221077</td>\n",
       "      <td>0.814425</td>\n",
       "      <td>-1.137179</td>\n",
       "      <td>-0.383026</td>\n",
       "      <td>0.779030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.947492</td>\n",
       "      <td>-0.858450</td>\n",
       "      <td>0.889916</td>\n",
       "      <td>-0.154925</td>\n",
       "      <td>-1.155625</td>\n",
       "      <td>0.015379</td>\n",
       "      <td>-1.105353</td>\n",
       "      <td>-0.648914</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>-1.540793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782183</td>\n",
       "      <td>-0.488197</td>\n",
       "      <td>-0.278391</td>\n",
       "      <td>0.728685</td>\n",
       "      <td>-0.763431</td>\n",
       "      <td>0.236582</td>\n",
       "      <td>0.955096</td>\n",
       "      <td>0.381789</td>\n",
       "      <td>0.078896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.114866</td>\n",
       "      <td>-0.185617</td>\n",
       "      <td>0.709929</td>\n",
       "      <td>-1.836072</td>\n",
       "      <td>0.618630</td>\n",
       "      <td>0.533485</td>\n",
       "      <td>-1.720446</td>\n",
       "      <td>1.623263</td>\n",
       "      <td>0.917968</td>\n",
       "      <td>0.928045</td>\n",
       "      <td>...</td>\n",
       "      <td>1.827681</td>\n",
       "      <td>-2.206419</td>\n",
       "      <td>1.144606</td>\n",
       "      <td>1.443290</td>\n",
       "      <td>-1.825984</td>\n",
       "      <td>0.728909</td>\n",
       "      <td>-0.316765</td>\n",
       "      <td>-1.749469</td>\n",
       "      <td>1.469583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.321062</td>\n",
       "      <td>1.081722</td>\n",
       "      <td>-0.164561</td>\n",
       "      <td>0.396199</td>\n",
       "      <td>-1.397152</td>\n",
       "      <td>-0.871771</td>\n",
       "      <td>1.122204</td>\n",
       "      <td>0.575904</td>\n",
       "      <td>-0.623351</td>\n",
       "      <td>-0.500386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369773</td>\n",
       "      <td>-0.634732</td>\n",
       "      <td>0.403437</td>\n",
       "      <td>-0.104299</td>\n",
       "      <td>-0.323933</td>\n",
       "      <td>-0.902700</td>\n",
       "      <td>-0.541509</td>\n",
       "      <td>0.194557</td>\n",
       "      <td>0.078778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.703655</td>\n",
       "      <td>-0.163321</td>\n",
       "      <td>1.217748</td>\n",
       "      <td>0.454795</td>\n",
       "      <td>-1.101793</td>\n",
       "      <td>1.813344</td>\n",
       "      <td>0.772095</td>\n",
       "      <td>0.809858</td>\n",
       "      <td>1.934706</td>\n",
       "      <td>1.319644</td>\n",
       "      <td>...</td>\n",
       "      <td>1.111579</td>\n",
       "      <td>-1.185462</td>\n",
       "      <td>-1.001437</td>\n",
       "      <td>1.146624</td>\n",
       "      <td>-0.712494</td>\n",
       "      <td>-0.639765</td>\n",
       "      <td>-0.657432</td>\n",
       "      <td>0.073911</td>\n",
       "      <td>0.039936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.507634</td>\n",
       "      <td>-0.474345</td>\n",
       "      <td>0.672943</td>\n",
       "      <td>-0.292255</td>\n",
       "      <td>-0.473265</td>\n",
       "      <td>1.308012</td>\n",
       "      <td>1.254812</td>\n",
       "      <td>0.274027</td>\n",
       "      <td>1.164615</td>\n",
       "      <td>-1.576352</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232129</td>\n",
       "      <td>0.443502</td>\n",
       "      <td>1.018157</td>\n",
       "      <td>1.087740</td>\n",
       "      <td>-0.377044</td>\n",
       "      <td>-0.213392</td>\n",
       "      <td>-1.178817</td>\n",
       "      <td>-1.092621</td>\n",
       "      <td>-0.255931</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.352013</td>\n",
       "      <td>1.221801</td>\n",
       "      <td>2.687534</td>\n",
       "      <td>0.659381</td>\n",
       "      <td>0.265156</td>\n",
       "      <td>0.230010</td>\n",
       "      <td>0.083122</td>\n",
       "      <td>0.734305</td>\n",
       "      <td>-0.733788</td>\n",
       "      <td>-0.910704</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.467103</td>\n",
       "      <td>0.030162</td>\n",
       "      <td>0.339514</td>\n",
       "      <td>-0.965498</td>\n",
       "      <td>0.316979</td>\n",
       "      <td>0.347530</td>\n",
       "      <td>2.105202</td>\n",
       "      <td>1.308912</td>\n",
       "      <td>-1.885200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-1.171216</td>\n",
       "      <td>-0.586673</td>\n",
       "      <td>-0.265622</td>\n",
       "      <td>-0.011660</td>\n",
       "      <td>1.148446</td>\n",
       "      <td>-0.239592</td>\n",
       "      <td>-1.477015</td>\n",
       "      <td>0.228663</td>\n",
       "      <td>1.831622</td>\n",
       "      <td>0.547303</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.163858</td>\n",
       "      <td>-1.356036</td>\n",
       "      <td>-0.460775</td>\n",
       "      <td>-0.572682</td>\n",
       "      <td>0.725528</td>\n",
       "      <td>-0.669803</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>-0.472407</td>\n",
       "      <td>-1.378803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0    2.149553   0.376510  -1.891904  -0.840981  -0.309501  -0.750899   \n",
       "1    0.030191   0.003084  -0.191048   0.192283  -0.024028  -0.463269   \n",
       "2   -1.240354   1.532933  -0.679733  -1.006590  -0.382227  -0.067230   \n",
       "3   -0.947492  -0.858450   0.889916  -0.154925  -1.155625   0.015379   \n",
       "4   -2.114866  -0.185617   0.709929  -1.836072   0.618630   0.533485   \n",
       "..        ...        ...        ...        ...        ...        ...   \n",
       "95   1.321062   1.081722  -0.164561   0.396199  -1.397152  -0.871771   \n",
       "96  -0.703655  -0.163321   1.217748   0.454795  -1.101793   1.813344   \n",
       "97   1.507634  -0.474345   0.672943  -0.292255  -0.473265   1.308012   \n",
       "98  -0.352013   1.221801   2.687534   0.659381   0.265156   0.230010   \n",
       "99  -1.171216  -0.586673  -0.265622  -0.011660   1.148446  -0.239592   \n",
       "\n",
       "    feature_6  feature_7  feature_8  feature_9  ...  feature_41  feature_42  \\\n",
       "0   -2.092533   1.166785   0.418648   0.026553  ...   -1.505302    0.662250   \n",
       "1    1.182454  -0.593840   0.449656   1.101156  ...    0.584503   -0.998030   \n",
       "2   -0.442423  -0.139050  -0.566511   0.289654  ...   -0.341175   -1.045214   \n",
       "3   -1.105353  -0.648914   0.843373  -1.540793  ...    0.782183   -0.488197   \n",
       "4   -1.720446   1.623263   0.917968   0.928045  ...    1.827681   -2.206419   \n",
       "..        ...        ...        ...        ...  ...         ...         ...   \n",
       "95   1.122204   0.575904  -0.623351  -0.500386  ...    0.369773   -0.634732   \n",
       "96   0.772095   0.809858   1.934706   1.319644  ...    1.111579   -1.185462   \n",
       "97   1.254812   0.274027   1.164615  -1.576352  ...   -0.232129    0.443502   \n",
       "98   0.083122   0.734305  -0.733788  -0.910704  ...   -0.467103    0.030162   \n",
       "99  -1.477015   0.228663   1.831622   0.547303  ...   -1.163858   -1.356036   \n",
       "\n",
       "    feature_43  feature_44  feature_45  feature_46  feature_47  feature_48  \\\n",
       "0     0.265463   -0.257552   -0.199983    1.454656   -2.043937   -2.478008   \n",
       "1    -0.241414   -0.709572   -0.135254    0.211817   -0.219444    1.347727   \n",
       "2    -1.320925    1.394625   -1.221077    0.814425   -1.137179   -0.383026   \n",
       "3    -0.278391    0.728685   -0.763431    0.236582    0.955096    0.381789   \n",
       "4     1.144606    1.443290   -1.825984    0.728909   -0.316765   -1.749469   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "95    0.403437   -0.104299   -0.323933   -0.902700   -0.541509    0.194557   \n",
       "96   -1.001437    1.146624   -0.712494   -0.639765   -0.657432    0.073911   \n",
       "97    1.018157    1.087740   -0.377044   -0.213392   -1.178817   -1.092621   \n",
       "98    0.339514   -0.965498    0.316979    0.347530    2.105202    1.308912   \n",
       "99   -0.460775   -0.572682    0.725528   -0.669803    0.008763   -0.472407   \n",
       "\n",
       "    feature_49  target  \n",
       "0     0.737513       1  \n",
       "1    -0.747078       1  \n",
       "2     0.779030       1  \n",
       "3     0.078896       1  \n",
       "4     1.469583       0  \n",
       "..         ...     ...  \n",
       "95    0.078778       1  \n",
       "96    0.039936       1  \n",
       "97   -0.255931       0  \n",
       "98   -1.885200       1  \n",
       "99   -1.378803       1  \n",
       "\n",
       "[100 rows x 51 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\PHANEENDRA\\Downloads\\synthetic_overfitting_dataset.csv\")\n",
    "# df=df.drop(columns='customerID')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2a21f49-14ff-4913-a89a-f6b2dacbe43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 51 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   feature_0   100 non-null    float64\n",
      " 1   feature_1   100 non-null    float64\n",
      " 2   feature_2   100 non-null    float64\n",
      " 3   feature_3   100 non-null    float64\n",
      " 4   feature_4   100 non-null    float64\n",
      " 5   feature_5   100 non-null    float64\n",
      " 6   feature_6   100 non-null    float64\n",
      " 7   feature_7   100 non-null    float64\n",
      " 8   feature_8   100 non-null    float64\n",
      " 9   feature_9   100 non-null    float64\n",
      " 10  feature_10  100 non-null    float64\n",
      " 11  feature_11  100 non-null    float64\n",
      " 12  feature_12  100 non-null    float64\n",
      " 13  feature_13  100 non-null    float64\n",
      " 14  feature_14  100 non-null    float64\n",
      " 15  feature_15  100 non-null    float64\n",
      " 16  feature_16  100 non-null    float64\n",
      " 17  feature_17  100 non-null    float64\n",
      " 18  feature_18  100 non-null    float64\n",
      " 19  feature_19  100 non-null    float64\n",
      " 20  feature_20  100 non-null    float64\n",
      " 21  feature_21  100 non-null    float64\n",
      " 22  feature_22  100 non-null    float64\n",
      " 23  feature_23  100 non-null    float64\n",
      " 24  feature_24  100 non-null    float64\n",
      " 25  feature_25  100 non-null    float64\n",
      " 26  feature_26  100 non-null    float64\n",
      " 27  feature_27  100 non-null    float64\n",
      " 28  feature_28  100 non-null    float64\n",
      " 29  feature_29  100 non-null    float64\n",
      " 30  feature_30  100 non-null    float64\n",
      " 31  feature_31  100 non-null    float64\n",
      " 32  feature_32  100 non-null    float64\n",
      " 33  feature_33  100 non-null    float64\n",
      " 34  feature_34  100 non-null    float64\n",
      " 35  feature_35  100 non-null    float64\n",
      " 36  feature_36  100 non-null    float64\n",
      " 37  feature_37  100 non-null    float64\n",
      " 38  feature_38  100 non-null    float64\n",
      " 39  feature_39  100 non-null    float64\n",
      " 40  feature_40  100 non-null    float64\n",
      " 41  feature_41  100 non-null    float64\n",
      " 42  feature_42  100 non-null    float64\n",
      " 43  feature_43  100 non-null    float64\n",
      " 44  feature_44  100 non-null    float64\n",
      " 45  feature_45  100 non-null    float64\n",
      " 46  feature_46  100 non-null    float64\n",
      " 47  feature_47  100 non-null    float64\n",
      " 48  feature_48  100 non-null    float64\n",
      " 49  feature_49  100 non-null    float64\n",
      " 50  target      100 non-null    int64  \n",
      "dtypes: float64(50), int64(1)\n",
      "memory usage: 40.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64ceb0c8-c59a-460e-94b4-be24cc0aacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(columns='target')\n",
    "y=df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0e8b42a-8adf-41e9-9c5d-730861dfc40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=pd.get_dummies(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "42fdc4a2-152a-40ff-9440-2afc84440ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "651b0d28-85ef-493d-9b8e-0083087037c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression().fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4091cb61-9747-4c1b-8522-27ceff16bec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb356b61-89e1-48d9-9960-208658648c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "02e5e8aa-3bfc-4d22-8e2e-2632abe19c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_reg=LogisticRegression(penalty='l1',solver='liblinear').fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0c35ace2-5ed7-4c6b-94f2-c4633371da88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9625"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_reg.score(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "028dd721-43a6-463a-aa8d-67e7373c9444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_reg.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b02c7-b0a1-443c-8264-718027165851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e246e7bf-f94e-4917-9c54-5117e8cdc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg=LogisticRegression(penalty='l2',solver='liblinear').fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c264360f-2bfc-4ec4-86c6-ae86858a75ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_reg.score(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bc47d28a-6a8c-4be0-bc3a-b4a9affd9ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_reg.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29482b2d-2045-468a-89af-7ff0b3803bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d20bd0d8-a56b-4965-bc2b-4366f648c6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.1}\n",
      "Train Score: 0.7625\n",
      "Test Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(LogisticRegression(penalty='l1', solver='liblinear'), param_grid, cv=5)\n",
    "grid.fit(xtrain, ytrain)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Train Score:\", grid.score(xtrain, ytrain))\n",
    "print(\"Test Score:\", grid.score(xtest, ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "54abe3ac-b5da-455d-9cc9-51f99dd1f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_reg2=LogisticRegression(C=0.1,penalty='l1',solver='liblinear').fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a6555672-d43b-48bd-95ea-f74ed864ef8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7625"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_reg2.score(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "60382d8d-0bb4-4efc-b610-be2344aad32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_reg2.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e1db0d-0f3f-4b7c-a3c8-00603e503c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7e5552d1-9f57-4089-a0f9-4c884fa926a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.1}\n",
      "Train Score: 0.9375\n",
      "Test Score: 0.7\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(LogisticRegression(penalty='l2', solver='liblinear'), param_grid, cv=5)\n",
    "grid.fit(xtrain, ytrain)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Train Score:\", grid.score(xtrain, ytrain))\n",
    "print(\"Test Score:\", grid.score(xtest, ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88513a40-a05d-487b-b798-67117d0227b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391f0795-3c46-440d-93dc-fe9c0efd32e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17724355-a6d7-4df9-96cb-247d4bb5f69d",
   "metadata": {},
   "source": [
    "# One more Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "eac62a01-164b-41b2-aafb-6a71137b6f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\PHANEENDRA\\Downloads\\heart_cleveland_upload.csv\")  # Use the downloaded path if needed\n",
    "\n",
    "# Add 50 random noise features\n",
    "np.random.seed(42)\n",
    "for i in range(50):\n",
    "    df[f'noise_{i}'] = np.random.rand(df.shape[0])\n",
    "\n",
    "# Save the new noisy dataset\n",
    "df.to_csv(r\"C:\\Users\\PHANEENDRA\\Downloads\\heart_cleveland_upload.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "10fb2866-24bc-4498-806f-820b43599dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['condition'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f32cf0ab-54f2-4876-95b2-4c310c166172",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[158], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Scale features\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m      7\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Train/test split\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Split features and target\n",
    "X = df.drop('condition', axis=1)\n",
    "y = df['condition']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806540f2-49ff-4e31-ba0c-43815bf1b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No regularization\n",
    "model_none = LogisticRegression(penalty='none', solver='saga', max_iter=5000)\n",
    "model_none.fit(X_train, y_train)\n",
    "train_acc_none = model_none.score(X_train, y_train)\n",
    "test_acc_none = model_none.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1c3d2a-381c-4943-ba94-89357ab562c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 regularization\n",
    "model_l1 = LogisticRegression(penalty='l1', solver='saga', C=0.1, max_iter=5000)\n",
    "model_l1.fit(X_train, y_train)\n",
    "train_acc_l1 = model_l1.score(X_train, y_train)\n",
    "test_acc_l1 = model_l1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c513432a-7ce8-4c1c-8a3f-71a43c167e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 regularization\n",
    "model_l2 = LogisticRegression(penalty='l2', solver='saga', C=0.1, max_iter=5000)\n",
    "model_l2.fit(X_train, y_train)\n",
    "train_acc_l2 = model_l2.score(X_train, y_train)\n",
    "test_acc_l2 = model_l2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef521d5-b79e-4b93-81ee-630977513aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"Model\\t\\tTrain Acc\\tTest Acc\\tOverfit Gap\")\n",
    "print(f\"No Reg\\t\\t{train_acc_none:.2f}\\t\\t{test_acc_none:.2f}\\t\\t{train_acc_none - test_acc_none:.2f}\")\n",
    "print(f\"L1 Reg\\t\\t{train_acc_l1:.2f}\\t\\t{test_acc_l1:.2f}\\t\\t{train_acc_l1 - test_acc_l1:.2f}\")\n",
    "print(f\"L2 Reg\\t\\t{train_acc_l2:.2f}\\t\\t{test_acc_l2:.2f}\\t\\t{train_acc_l2 - test_acc_l2:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
